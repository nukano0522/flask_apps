{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nukan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, BertJapaneseTokenizer, BertModel\n",
    "from torch import cuda\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from transformers import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "max_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27日に生放送された日本テレビ「バンクーバー2010」には、女子フィギュアスケートで銀メダル...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>「腐女子」という言葉をご存知でしょうか。\\nいわゆる漫画やアニメキャラなどの男性同士の恋愛（...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>展示会イベント恒例のおねいさん写真のコーナーでございます \\n\\n国内最大級の携帯電話や無線...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>芸能界を引退した島田紳助さんが、今月２８日に公開される映画「犬の首輪とコロッケと」に声だけ出...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>お花に包まれた洋館で、イケメン執事に囲まれながら、ゆったりと過ごす午後のひととき……。女の子...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  27日に生放送された日本テレビ「バンクーバー2010」には、女子フィギュアスケートで銀メダル...         7\n",
       "1  「腐女子」という言葉をご存知でしょうか。\\nいわゆる漫画やアニメキャラなどの男性同士の恋愛（...         0\n",
       "2  展示会イベント恒例のおねいさん写真のコーナーでございます \\n\\n国内最大級の携帯電話や無線...         6\n",
       "3  芸能界を引退した島田紳助さんが、今月２８日に公開される映画「犬の首輪とコロッケと」に声だけ出...         2\n",
       "4  お花に包まれた洋館で、イケメン執事に囲まれながら、ゆったりと過ごす午後のひととき……。女の子...         5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"livedoor_text.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
    "model = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\", output_attentions=False, output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "  def __init__(self, X, tokenizer, max_len):\n",
    "    self.X = X\n",
    "    # self.y = y\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return 1\n",
    "\n",
    "  def encode(self, tokenizer, text):\n",
    "      inputs = tokenizer.encode_plus(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          padding = 'max_length',\n",
    "          truncation = True\n",
    "      )\n",
    "      return inputs\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    text = self.X[index]\n",
    "    # label = self.y[index]\n",
    "    ids = []\n",
    "    mask = []\n",
    "    inputs = self.encode(tokenizer=self.tokenizer, text=text)\n",
    "    ids.append(torch.LongTensor(inputs['input_ids']))\n",
    "    mask.append(torch.LongTensor(inputs['attention_mask']))\n",
    "\n",
    "    return {\n",
    "      'ids': ids,\n",
    "      'mask': mask,\n",
    "      # 'label': label,\n",
    "      'text':text,\n",
    "      # 'userID':userID\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[\"text\"].values[[0]]\n",
    "# X\n",
    "\n",
    "text = '27日に生放送された日本テレビ「バンクーバー2010」には、女子フィギュアスケートで銀メダルを獲得した浅田真央が出演した。\\n\\nメダルを獲得しながらも、自身の演技に満足できず悔し涙を流した運命の日から一夜明け、プレッシャーから解放された安堵感からか、いつもの笑顔がみられるようになった浅田。五輪史上初となる3度のトリプルアクセル（3回転半）を成功させたことには、「今シーズンから3回飛ぶって決めてましたし、それをやりたいっていう思いがあったのでオリンピックで挑戦というよりは、やってきたことを出したいという思いが強かったです」と語った。\\n\\nまた、五輪という舞台については、「予想していたよりも、すごい大きな舞台だったんだなって、終わってから改めて感じました」と振り返る浅田は、同番組が生放送されることで出演前から緊張していた点に話が及ぶと、「生なんだと。流れてるんだと、日本で・・・」と苦笑いを浮かべた。'\n",
    "X = np.array([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = CreateDataset(X, tokenizer, max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [tensor([    2,   971,    32,     7,   128,   333,    26,    20,    10,  5038,\n",
       "             36, 14353,   785,    38,     7,     9,     6,  1568,  6710,  5461,\n",
       "             12,  8828,    11,   906,    15,    10,  2752, 28675,   841, 29210,\n",
       "             14,   793,    15,    10,     8,  6976,    11,   906,    15,   895,\n",
       "             28,     6,   901,     5,  5913,     7,  9109,   203,   255, 16977,\n",
       "          28454, 30557,    11,  8272,    10,  9585,     5,    32,    40, 19239,\n",
       "           9073,     6, 25204,    40,  3766,    26,    20,    10, 18984,   832,\n",
       "             40,    29,     6,  9749,     5, 18802,    14,   546,   342,   124,\n",
       "              7,    58,    10,  2752, 28675,     8,  8111,  2737,   176,    13,\n",
       "            139,    48,   559,     5, 18052, 20614,    23,    48,  3232,   818,\n",
       "             24,    11,  1320,    26,   191,    10,    45,     7,     9,     6,\n",
       "             36,   744,   712,    40,    48,   198, 14856,  6172,  2372,    16,\n",
       "           3913,    10,    15,     6,   218,    11,  4710,  1549,  6172,  9366,\n",
       "           2502,    14,   102,    10,   947,  1707,    12,  3073,    13,   625,\n",
       "            221,     9,     6,  9665,    10,    45,    11,  2078,  1549,   140,\n",
       "           2502,    14, 14973,    10,  2992,    38,    13,  2686,    10,     8,\n",
       "            106,     6,  8111,   140,  1693,   362,     9,     6,    36,  4663,\n",
       "             15,    16,    21,    10,   221,    28,     6, 25675,  1200,  1693,\n",
       "            308,    10,  1058,    75,    18,  6172,     6,  2764,    16,    40,\n",
       "           7656,  3415,  3913,    10,    38,    13, 28110,  2752, 28675,     9,\n",
       "              6,    69,   486,    14,   128,   333,    26,    62,    45,    12,\n",
       "            793,   174,    40, 10204,    15,    16,    21,    10,   652,     7,\n",
       "            735,    14,  5905,    13,     6,    36,   128,    18,  1058,    75,\n",
       "             13,     8,  2066,  7134,  1058,    75,    13,     6,    91,    12,\n",
       "             35,    35,    35,    38,    13,  2155,  7674,    11, 10357, 28844,\n",
       "             10,     8,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0])],\n",
       " 'mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0])],\n",
       " 'text': '27日に生放送された日本テレビ「バンクーバー2010」には、女子フィギュアスケートで銀メダルを獲得した浅田真央が出演した。\\n\\nメダルを獲得しながらも、自身の演技に満足できず悔し涙を流した運命の日から一夜明け、プレッシャーから解放された安堵感からか、いつもの笑顔がみられるようになった浅田。五輪史上初となる3度のトリプルアクセル（3回転半）を成功させたことには、「今シーズンから3回飛ぶって決めてましたし、それをやりたいっていう思いがあったのでオリンピックで挑戦というよりは、やってきたことを出したいという思いが強かったです」と語った。\\n\\nまた、五輪という舞台については、「予想していたよりも、すごい大きな舞台だったんだなって、終わってから改めて感じました」と振り返る浅田は、同番組が生放送されることで出演前から緊張していた点に話が及ぶと、「生なんだと。流れてるんだと、日本で・・・」と苦笑いを浮かべた。'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = next(iter(dataloader_test))\n",
    "# tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class BertForLivedoor(nn.Module):\n",
    "    '''BERTモデルにLivedoorニュースの9クラスを判定する部分をつなげたモデル'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BertForLivedoor, self).__init__()\n",
    "\n",
    "        # BERTモジュール\n",
    "        self.bert = model  # 日本語学習済みのBERTモデル\n",
    "\n",
    "        # headにクラス予測を追加\n",
    "        # 入力はBERTの出力特徴量の次元768、出力は9クラス\n",
    "        self.cls = nn.Linear(in_features=768, out_features=9)\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.cls.weight, std=0.02)\n",
    "        nn.init.normal_(self.cls.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        '''\n",
    "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
    "        '''\n",
    "\n",
    "        # BERTの基本モデル部分の順伝搬\n",
    "        # 順伝搬させる\n",
    "        result = self.bert(input_ids)  # reult は、sequence_output, pooled_output\n",
    "\n",
    "        # sequence_outputの先頭の単語ベクトルを抜き出す\n",
    "        vec_0 = result[0]  # 最初の0がsequence_outputを示す\n",
    "        vec_0 = vec_0[:, 0, :]  # 全バッチ。先頭0番目の単語の全768要素\n",
    "        vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_size]に変換\n",
    "        output = self.cls(vec_0)  # 全結合層\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cpu\n"
     ]
    }
   ],
   "source": [
    "# GPUが使えるかを確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス：\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデル読み込み\n",
    "net_trained = BertForLivedoor()\n",
    "\n",
    "save_path = \"./single_bert_fine_tuning_livedoor.pth\"\n",
    "net_trained.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "pred: tensor([7])\n",
      "pred: 7\n"
     ]
    }
   ],
   "source": [
    "# ミニバッチの用意\n",
    "batch = next(iter(dataloader_test))\n",
    "\n",
    "# GPUが使えるならGPUにデータを送る\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "inputs = batch[\"ids\"][0].to(device)  # 文章\n",
    "\n",
    "outputs = net_trained(inputs)\n",
    "_, pred = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "print(f\"pred: {pred}\")\n",
    "print(f\"pred: {pred.to('cpu').detach().numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8249, -1.1255, -1.5014, -1.5047, -1.0651, -0.1506, -2.5921,  7.0584,\n",
       "          2.5893]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f80fd9d970a87e3bab28be483655659e5de72141ad554ade49a08f6532b9ba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
